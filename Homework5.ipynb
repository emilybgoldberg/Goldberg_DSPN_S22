{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szkkhiCZDF52"
   },
   "source": [
    "# Homework 5:  Linear models, continued\n",
    "This homework assignment is designed to give you a deeper understanding of linear models. First, we'll dive into the math behind the closed-form solution of maximum likelihood estimation. **In the first section below, write your answers using Latex equation formatting.**\n",
    "\n",
    "*Note: Check out [this page](https://gtribello.github.io/mathNET/assets/notebook-writing.html) and [this page](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) for resources on how to do Latex formatting. You can also double click on the question cells in this notebook to see how math is formatted in the questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJscNReoylRt"
   },
   "source": [
    "---\n",
    "## 1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH82gwuymPi0"
   },
   "source": [
    "Using the mean squared error (MSE) as your objective function (the thing you're trying to minimize when you fit your model) allows for a closed form solution to finding the maximum likelihood estimate (MLE) of your model parameters in linear regression. Letâ€™s consider the simple, single predictor variable model, i.e. simple linear regression :  $Y= \\beta_0 + \\beta_1 X $. \n",
    "\n",
    "a) Use algebra to show how you can expand out $MSE(\\beta_0, \\beta_1)$ to get from i to ii below.\n",
    "\n",
    "> _i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$\n",
    "\n",
    "> _ii)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn2hveNho-Of"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "> The original equation in this problem is $$E[Y-(\\beta_0 + \\beta_1X))^2 $$\n",
    "\n",
    "Expressed differently: \n",
    "$$ E[(Y-(\\beta_0 + \\beta_1X))] E[(Y-(\\beta_0 + \\beta_1X))] $$\n",
    "\n",
    "**NOTE: for ease of calculation will remove E[ ] and add back in at end.** \n",
    "\n",
    "$ Y(Y-(\\beta_0 + \\beta_1X)) - (\\beta_0 + \\beta_1X)(Y-(\\beta_0 + \\beta_1X)) $\n",
    "\n",
    "$ Y^2 - Y(\\beta_0 + \\beta_1X) - Y (\\beta_0 + \\beta_1X) + (\\beta_0 + \\beta_1X)^2$\n",
    "\n",
    "$ Y^2 - Y\\beta_0 - Y\\beta_1X - Y\\beta_0 - Y\\beta_1X + (\\beta_0 + \\beta_1X)(\\beta_0 + \\beta_1X)$\n",
    "\n",
    "$ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0(\\beta_0 + \\beta_1X) + \\beta_1X(\\beta_0 + \\beta_1X)$\n",
    "\n",
    "$ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0^2 + \\beta_0\\beta_1X + \\beta_0\\beta_1X + (\\beta_1X)^2$\n",
    "\n",
    "$ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0^2 + 2\\beta_0\\beta_1X + \\beta_1^2X^2$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**(adding E [ ] back in to the equation)**\n",
    "\n",
    "$ E[ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0^2 + 2\\beta_0\\beta_1X + \\beta_1^2X^2 ]$\n",
    "\n",
    "$ E[Y^2] - E[2Y\\beta_0] - E[2Y\\beta_1X] + \\beta_0^2 + E[2\\beta_0\\beta_1X] + E[\\beta_1^2X^2]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**Important to also mention and reference here:**\n",
    "\n",
    "$ cov(X,Y) = E[XY] - E[X]E[Y]$\n",
    "\n",
    "Thus the following is also true:   \n",
    "\n",
    "$ E[XY] = cov(X,Y) + E[X]E[Y]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "Additionally: \n",
    "\n",
    "$ var (X) = E[X^2] - E[X]^2$\n",
    "\n",
    "Thus the following is also true:\n",
    "\n",
    "$ E[X^2] = var(X) + E[X]^2$\n",
    "\n",
    "This is important as some of these rules and terms can now be applied to the most recent expansion of this problem: \n",
    "\n",
    "$$ E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1cov(X,Y) - 2\\beta_1E[X]E[Y] + \\beta_0^2 + 2\\beta_0\\beta_1E[X] + \\beta_1^2 (var[X]) + \\beta_1^2(E[X])^2 $$\n",
    "\n",
    "With this, I have arrived at equation *ii*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCr46r9xwRXP"
   },
   "source": [
    "b) Prove that the MLE of $\\beta_0$ is $E[Y]- \\beta_1 E[X]$ by taking the derivative of _ii_ above, with respect to $\\beta_0$, setting the derivative to zero, and solving for $\\beta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul-PZyLbwTCQ"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "What I'm going to do is pull down equation *ii* from above and take the derivative with respect to Beta_0. In this process, terms without Beta_0 included will be dropped (but, for example, terms with both Beta_0 and Beta_1 are retained). Once I simplify the equation I will take derivatives with respect to Beta_0. Finally I'll set Beta_0 to equal 0. \n",
    "\n",
    "Beginning point: \n",
    "\n",
    "$ E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1cov(X,Y) - 2\\beta_1E[X]E[Y] + \\beta_0^2 + 2\\beta_0\\beta_1E[X] + \\beta_1^2 (var[X]) + \\beta_1^2(E[X])^2 $\n",
    "\n",
    "The following terms from this equation will be dropped: \n",
    "\n",
    "$ E[Y^2]$\n",
    "\n",
    "$ -2\\beta_1cov[X,Y]$\n",
    "\n",
    "$ -2\\beta_1E[X]E[Y]$\n",
    "\n",
    "$ \\beta_1^2var[X]$\n",
    "\n",
    "$ \\beta_1^2E[X]^2$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "This leaves us with: \n",
    "\n",
    "$ -2\\beta_0E[Y] + \\beta_0^2 + 2\\beta_0\\beta_1E[X]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "For each term I will show the process of taking the derivative separately and then merge the final terms in my next step: \n",
    "\n",
    "First term: \n",
    "\n",
    "$ -2\\beta_0E[Y] =$\n",
    "\n",
    "$-2\\beta_0^1E[Y] =$\n",
    "\n",
    "$1*-2\\beta_0^{1-1}E[Y] =$\n",
    "\n",
    "$1*-2\\beta_0^0E[Y] =$\n",
    "\n",
    "$1*-2*E[Y] =$\n",
    "\n",
    "$ -2E[Y]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Second term: \n",
    "$\\beta_0^2 =$\n",
    "\n",
    "$2*\\beta_0^{2-1} =$\n",
    "\n",
    "$2*\\beta_0^1 =$\n",
    "\n",
    "$2\\beta_0$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Third term: \n",
    "$ 2\\beta_0\\beta_1E[X]= $\n",
    "\n",
    "$ 2\\beta_0^1\\beta_1E[X] = $\n",
    "\n",
    "$ 1*2\\beta_0^{1-1}\\beta_1E[X] = $\n",
    "\n",
    "$ 1*2\\beta_0^0\\beta_1E[X] = $\n",
    "\n",
    "$ 2\\beta_1E[X]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Thus, our derivative with respect to Beta_0 is: \n",
    "$ f(\\beta_0) = -2E[Y] + 2\\beta_0 + 2\\beta_1E[X]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "Setting f(Beta_0) to 0, I can solve for Beta_0: \n",
    "$ -2E[Y] + 2\\beta_0 + 2\\beta_1E[X] = 0 $\n",
    "\n",
    "$ 2(-E[Y] + \\beta_0 + \\beta_1E[X]) = 0$\n",
    "\n",
    "$ \\frac{2(-E[Y] + \\beta_0 + \\beta_1E[X])}{2} = \\frac{0}{2}$\n",
    "\n",
    "$ -E[Y] + \\beta_0 + \\beta_1E[X] = 0$\n",
    "\n",
    "$ -E[Y] + \\beta_0 -\\beta_0 + \\beta_1E[X] = 0 -\\beta_0$\n",
    "\n",
    "$ -\\beta_0 = -E[Y]+ \\beta_1E[X]$\n",
    "\n",
    "$ \\frac{-\\beta_0}{-1} = \\frac{(-E[Y]+ \\beta_1E[X])}{-1}$\n",
    "\n",
    "$$ \\beta_0 = E[Y] - \\beta_1E[X]$$\n",
    "\n",
    "With this, I have arrived to the conclusion that MLE of Beta_0 is equal to the equation listed in the instructions for part 1B. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uv4Z7afw4gB"
   },
   "source": [
    "c) Prove that the MLE for $\\beta_1$ is $Cov[X,Y]/Var[X]$ by taking the derivative of equation _ii_ above, with respect to $\\beta_1$, setting the derivative to zero, and solving for $\\beta_1$. *Hint: after you've simplified / expanded a bit, plug in the solution for $\\beta_0$ from part b.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWTFZ6ZSw6sh"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Again I'm going to pull down equation *ii* from above and take the derivative with respect to Beta_1. In this process, terms without Beta_1 will be dropped (but, for example, terms with both Beta_0 and Beta_1 are retained). Once I simplify the equation I will take derivatives with respect to Beta_1. Finally I'll set Beta_1 to equal 0.\n",
    "\n",
    "The following terms from this equation will be dropped:\n",
    "\n",
    "$E[Y^2]$\n",
    "\n",
    "$-2\\beta_0E[Y]$\n",
    "\n",
    "$ \\beta_0^2$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "This leaves us with: \n",
    "\n",
    "$ -2\\beta_1cov(X,Y) - 2\\beta_1E[X]E[Y] + 2\\beta_0\\beta_1E[X] + \\beta_1^2var(X) + \\beta_1^2E[X]^2$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "For each term I will show the process of taking the derivative separately and then merge the final terms in my next step:\n",
    "<p>&nbsp;</p>\n",
    "First term: \n",
    "\n",
    "$ -2\\beta_1cov(X,Y) =$\n",
    "\n",
    "$ -2\\beta_1^1cov(X,Y) =$\n",
    "\n",
    "$ 1 * -2\\beta_1^{1-1}cov(X,Y) =$\n",
    "\n",
    "$ 1 * -2\\beta_1^0cov(X,Y) =$\n",
    "\n",
    "$ -2cov(X,Y)$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Second term: \n",
    "\n",
    "$ - 2\\beta_1E[X]E[Y] =$\n",
    "\n",
    "$ -2\\beta_1^1E[X]E[Y] =$\n",
    "\n",
    "$ 1 * -2 \\beta_1^{1-1}E[X]E[Y] =$\n",
    "\n",
    "$ 1* -2 \\beta_1^0 E[X]E[Y] =$\n",
    "\n",
    "$ -2E[X]E[Y]$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Third term: \n",
    "\n",
    "$ 2\\beta_0\\beta_1E[X]$\n",
    "\n",
    "$ 2\\beta_0\\beta_1^1E[X]$\n",
    "\n",
    "$ 1*2\\beta_0\\beta_1^{1-1}E[X]$\n",
    "\n",
    "$ 1*2\\beta_0\\beta_1^0E[X]$\n",
    "\n",
    "$ 2\\beta_0E[X]$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Fourth term: \n",
    "$\\beta_1^2var(X)$\n",
    "\n",
    "$ 2\\beta_1^{2-1}var(X)$\n",
    "\n",
    "$2\\beta_1^1var(X)$\n",
    "\n",
    "$2\\beta_1var(X)$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Fifth term: \n",
    "$\\beta_1^2E[X]^2$\n",
    "\n",
    "$2\\beta_1^{2-1}E[X]^2$\n",
    "\n",
    "$2\\beta_1^1E[X]^2$\n",
    "\n",
    "$2\\beta_1E[X]^2$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Thus, our derivative with respect to Beta_1 is:\n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) - 2E[X]E[Y] + 2\\beta_0E[X] + 2\\beta_1var(X) + 2\\beta_1E[(X)]^2$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Next I am going to use the equation generated in part 1B and plug in my answer for part 1B as a Beta_0 equivalent. The only difference between the equation below and equation above is that instead of Beta_0 in the 3rd term, you see the Beta_0 derivative (see part 1B).  \n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) -2E[X]E[Y] + 2E[X](E[Y] - \\beta_1E[X]) + 2\\beta_1var(X) + 2\\beta_1E[X]^2 $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Next I'm going to distribute 2E[X] in the 3rd term: \n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) -2E[X]E[Y] + 2E[X]E[Y] - 2\\beta_1E[X]^2 + 2\\beta_1var(X) + 2\\beta_1E[X]^2 $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "I can combine some terms with each other, effectively eliminating them, to reduce this equation: \n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) + 2\\beta_1var(X) $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Now I'll set the derivative of Beta_1 to 0 and solve for Beta_1:\n",
    "\n",
    "$ -2cov(X,Y) + 2\\beta_1var(X) = 0 $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Pull out 2 from both terms: \n",
    "\n",
    "$ 2(-cov(X,Y) + \\beta_1var(X)) = 0$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Divide both sides of equation by 2: \n",
    "\n",
    "$ \\frac{2(-cov(X,Y) + \\beta_1var(X))}{2} = \\frac{0}{2}$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Begin to isolate Beta_1 but adding Cov(X,Y) to both sides of the equation: \n",
    "\n",
    "$ -cov(X,Y) + cov(X,Y) + \\beta_1var(X) = 0 + cov(X,Y)$\n",
    "\n",
    "$ \\beta_1var(X) = cov(X,Y)$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Divide both sides of the equation by var(X) to isoalte Beta_1:\n",
    "$ \\frac{\\beta_1var(X)}{var(X)} = \\frac{cov(X,Y)}{var(X)}$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "We are left with: \n",
    "    <p>&nbsp;</p>\n",
    "\n",
    "$$ \\beta_1 = \\frac{cov(X,Y)}{var(X)}$$\n",
    "\n",
    "With this, I have arrived to the conclusion that MLE of Beta_1 is equal to the equation listed in the instructions for part 1C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66X264ZpDF58"
   },
   "source": [
    "---\n",
    "## 2. Connecting to data (4 points)\n",
    "\n",
    "Now let's connect this to some real data. Once again we'll be using the  **unrestricted_trimmed_1_7_2020_10_50_44.csv** file from the *Homework/hcp_data* folder in the class GitHub repository. \n",
    "\n",
    "â€‹\n",
    "This data is a portion of the [Human Connectome Project database](http://www.humanconnectomeproject.org/). It provides measures of cognitive tasks and brain morphology measurements from 1206 participants. The full description of each variable is provided in the **HCP_S1200_DataDictionary_April_20_2018.csv** file in the *Homework/hcp_data* folder in the class GitHub repository. \n",
    "\n",
    "a) Use the `setwd` and `read.csv` functions to load data from the **unrestricted_trimmed_1_7_2020_10_50_44.csv** file. Then use the `tidyverse` tools make a new dataframe `d1` that only inclues the subject ID (`Subject`), Flanker Task performance (`Flanker_Unadj`), and total grey matter volume (`FS_Total_GM_Vol`) variables and remove all _NA_ values.\n",
    "\n",
    "Use the `head` function to look at the first few rows of each data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5637,
     "status": "ok",
     "timestamp": 1616440721755,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "PZ0lngBjDF58",
    "outputId": "a3c4f688-d665-4d79-8250-56c4d45465e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 Ã— 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>n_NA</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 Ã— 1\n",
       "\\begin{tabular}{l}\n",
       " n\\_NA\\\\\n",
       " <int>\\\\\n",
       "\\hline\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 Ã— 1\n",
       "\n",
       "| n_NA &lt;int&gt; |\n",
       "|---|\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  n_NA\n",
       "1 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 Ã— 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>n_NA</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 Ã— 1\n",
       "\\begin{tabular}{l}\n",
       " n\\_NA\\\\\n",
       " <int>\\\\\n",
       "\\hline\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 Ã— 1\n",
       "\n",
       "| n_NA &lt;int&gt; |\n",
       "|---|\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  n_NA\n",
       "1 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 Ã— 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Subject</th><th scope=col>Flanker_Unadj</th><th scope=col>FS_Total_GM_Vol</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>100206</td><td>130.42</td><td>807245</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>100307</td><td>112.56</td><td>664124</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>100408</td><td>121.18</td><td>726206</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>100610</td><td>126.53</td><td>762308</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>101006</td><td>101.85</td><td>579632</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>101107</td><td>107.04</td><td>665024</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 Ã— 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Subject & Flanker\\_Unadj & FS\\_Total\\_GM\\_Vol\\\\\n",
       "  & <int> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t1 & 100206 & 130.42 & 807245\\\\\n",
       "\t2 & 100307 & 112.56 & 664124\\\\\n",
       "\t3 & 100408 & 121.18 & 726206\\\\\n",
       "\t4 & 100610 & 126.53 & 762308\\\\\n",
       "\t5 & 101006 & 101.85 & 579632\\\\\n",
       "\t6 & 101107 & 107.04 & 665024\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 Ã— 3\n",
       "\n",
       "| <!--/--> | Subject &lt;int&gt; | Flanker_Unadj &lt;dbl&gt; | FS_Total_GM_Vol &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 100206 | 130.42 | 807245 |\n",
       "| 2 | 100307 | 112.56 | 664124 |\n",
       "| 3 | 100408 | 121.18 | 726206 |\n",
       "| 4 | 100610 | 126.53 | 762308 |\n",
       "| 5 | 101006 | 101.85 | 579632 |\n",
       "| 6 | 101107 | 107.04 | 665024 |\n",
       "\n"
      ],
      "text/plain": [
       "  Subject Flanker_Unadj FS_Total_GM_Vol\n",
       "1 100206  130.42        807245         \n",
       "2 100307  112.56        664124         \n",
       "3 100408  121.18        726206         \n",
       "4 100610  126.53        762308         \n",
       "5 101006  101.85        579632         \n",
       "6 101107  107.04        665024         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "setwd(\"~/Documents/GitHub/Goldberg_DSPN_S22/hcp_data\")\n",
    "hcp_df1 <- read.csv(\"unrestricted_trimmed_1_7_2020_10_50_44.csv\")\n",
    "\n",
    "hcp_df1 %>% select(Subject, Flanker_Unadj, FS_Total_GM_Vol) %>%\n",
    "drop_na() -> d1\n",
    "\n",
    "## Count # of NAs within the Flanker_unadj variable\n",
    "summarize(d1, n_NA = sum(is.na(Flanker_Unadj)))\n",
    "## 0, yay!\n",
    "\n",
    "## Count # of NAs within the FS_Total_GM_Vol variable\n",
    "summarize(d1, n_NA = sum(is.na(FS_Total_GM_Vol)))\n",
    "## 0, yay!\n",
    "\n",
    "## Avital shared with me more straightforward way to check this: \n",
    "is.na(d1) %>% any\n",
    "## False, nice!\n",
    "\n",
    "head(d1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3owDQ0U2Ewn"
   },
   "source": [
    "b) Now we're going to see if the solutions we proved above actually line up with the model fit that R gives us (it should...). Calculate what the $\\beta_0$ and $\\beta_1$ coefficients should be for a simple linear regression model using `Flanker_Unadj` as $Y$ and `FS_Total_GM_Vol` as $X$. Use the formulas we derived above ($\\beta_1 = Cov[XY]/Var[X]$ , $\\beta_0 = E[Y] - \\beta_1E[X]$). Then use `lm()` to compare the coefficients you calculated with the ones R gives you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1614907277511,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 300
    },
    "id": "mWvD8shRDF5_",
    "outputId": "02f91143-c36c-4e9d-dce1-d81f4cbd71b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.10996547106463e-05"
      ],
      "text/latex": [
       "3.10996547106463e-05"
      ],
      "text/markdown": [
       "3.10996547106463e-05"
      ],
      "text/plain": [
       "[1] 3.109965e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "90.2564608190943"
      ],
      "text/latex": [
       "90.2564608190943"
      ],
      "text/markdown": [
       "90.2564608190943"
      ],
      "text/plain": [
       "[1] 90.25646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Flanker_Unadj ~ FS_Total_GM_Vol, data = hcp_df1)\n",
       "\n",
       "Coefficients:\n",
       "    (Intercept)  FS_Total_GM_Vol  \n",
       "      9.026e+01        3.110e-05  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Creating vectors for X (FS_Total_GM_Vol) and Y (Flanker_Unadj)\n",
    "X <- d1$FS_Total_GM_Vol\n",
    "Y <- d1$Flanker_Unadj\n",
    "\n",
    "## First I'm going to calculate the Beta_1 coefficient. There are 2 terms we need to calculate Beta_1:\n",
    "## First we need Cov(X,Y). Second we need Var(X).\n",
    "## We know that Cov(X,Y) = E[(X-EX)(Y-EY)]. \n",
    "## We also know that Var(X) is equal to E[(X-EX)^2]\n",
    "## E here can be taken to mean the average. Thus I am going to assign these equations to functions\n",
    "## and use those functions to calculate Beta_1:\n",
    "\n",
    "covXY <- mean((X-mean(X))*(Y-mean(Y)))\n",
    "varX <- mean((X-mean(X))^2)\n",
    "\n",
    "Beta_1 = covXY/varX\n",
    "Beta_1\n",
    "## Beta_1 = 3.11e-05\n",
    "\n",
    "## Next I am going to calculate the Beta_0 coefficient using the Beta_1 coefficient derived above. \n",
    "## Beta_0 is equal to the mean of Y minus the Beta_1 coefficient times the mean of (X). \n",
    "\n",
    "Beta_0 = mean(Y)-(Beta_1*(mean(X)))\n",
    "Beta_0\n",
    "## Beta_0 = 90.26\n",
    "\n",
    "\n",
    "## Now I am going to check my calculations by generating a simple linear model predicting\n",
    "## Y from X and comparing the model coefficients with the coefficients calculated above: \n",
    "\n",
    "lm(Flanker_Unadj ~ FS_Total_GM_Vol, data = hcp_df1)\n",
    "\n",
    "## The intercept value, also known as Beta_0, per the linear model is equal to 9.026e+01 = 90.26. \n",
    "## This is consistent with my calculated Beta_0 above.\n",
    "\n",
    "## The Beta_1 coefficient is equal to 3.110e-05, which is also consistent with my calculated\n",
    "## Beta_1 above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcnXbsZvDF6B"
   },
   "source": [
    "**DUE:** 5pm EST, March 15, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG5swCweDF6B"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> Monique Tardif (world traveler, volleyball queen), Avital Pelakh, Sara Jaramillo, Danielle Fox, Elie Ketura\n",
    "\n",
    "> Special shoutout to my very kind and patient boyfriend, Matthew Schnur, for teaching me calculus basics. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework5_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
