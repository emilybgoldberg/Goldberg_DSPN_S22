{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szkkhiCZDF52"
   },
   "source": [
    "# Homework 5:  Linear models, continued\n",
    "This homework assignment is designed to give you a deeper understanding of linear models. First, we'll dive into the math behind the closed-form solution of maximum likelihood estimation. **In the first section below, write your answers using Latex equation formatting.**\n",
    "\n",
    "*Note: Check out [this page](https://gtribello.github.io/mathNET/assets/notebook-writing.html) and [this page](https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd) for resources on how to do Latex formatting. You can also double click on the question cells in this notebook to see how math is formatted in the questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJscNReoylRt"
   },
   "source": [
    "---\n",
    "## 1. Deriving the Maximum Likelihood Estimate for Simple Linear Regression (6 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH82gwuymPi0"
   },
   "source": [
    "Using the mean squared error (MSE) as your objective function (the thing you're trying to minimize when you fit your model) allows for a closed form solution to finding the maximum likelihood estimate (MLE) of your model parameters in linear regression. Letâ€™s consider the simple, single predictor variable model, i.e. simple linear regression :  $Y= \\beta_0 + \\beta_1 X $. \n",
    "\n",
    "a) Use algebra to show how you can expand out $MSE(\\beta_0, \\beta_1)$ to get from i to ii below.\n",
    "\n",
    "> _i)_ $E[ (Y-(\\beta_0 + \\beta_1 X))^2]$\n",
    "\n",
    "> _ii)_ $E[Y^2] -2 \\beta_0E[Y]-2 \\beta_1 Cov[X,Y]-2 \\beta_1 E[X]E[Y]+ \\beta_0^2 +2 \\beta_0 \\beta_1 E[X]+\\beta_1^2 Var[X]+ \\beta_1^2 (E[X])^2$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn2hveNho-Of"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "> The original equation in this problem is $$E[Y-(\\beta_0 + \\beta_1X))^2 $$\n",
    "\n",
    "Expressed differently: \n",
    "$$ E[(Y-(\\beta_0 + \\beta_1X))] E[(Y-(\\beta_0 + \\beta_1X))] $$\n",
    "\n",
    "**NOTE: for ease of calculation will remove E[ ] and add back in at end.** \n",
    "\n",
    "$ Y(Y-(\\beta_0 + \\beta_1X)) - (\\beta_0 + \\beta_1X)(Y-(\\beta_0 + \\beta_1X)) $\n",
    "\n",
    "$ Y^2 - Y(\\beta_0 + \\beta_1X) - Y (\\beta_0 + \\beta_1X) + (\\beta_0 + \\beta_1X)^2$\n",
    "\n",
    "$ Y^2 - Y\\beta_0 - Y\\beta_1X - Y\\beta_0 - Y\\beta_1X + (\\beta_0 + \\beta_1X)(\\beta_0 + \\beta_1X)$\n",
    "\n",
    "$ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0(\\beta_0 + \\beta_1X) + \\beta_1X(\\beta_0 + \\beta_1X)$\n",
    "\n",
    "$ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0^2 + \\beta_0\\beta_1X + \\beta_0\\beta_1X + (\\beta_1X)^2$\n",
    "\n",
    "$ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0^2 + 2\\beta_0\\beta_1X + \\beta_1^2X^2$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**(adding E [ ] back in to the equation)**\n",
    "\n",
    "$ E[ Y^2 - 2Y\\beta_0 - 2Y\\beta_1X + \\beta_0^2 + 2\\beta_0\\beta_1X + \\beta_1^2X^2 ]$\n",
    "\n",
    "$ E[Y^2] - E[2Y\\beta_0] - E[2Y\\beta_1X] + \\beta_0^2 + E[2\\beta_0\\beta_1X] + E[\\beta_1^2X^2]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "**Important to also mention and reference here:**\n",
    "\n",
    "$ cov(X,Y) = E[XY] - E[X]E[Y]$\n",
    "\n",
    "Thus the following is also true:   \n",
    "\n",
    "$ E[XY] = cov(X,Y) + E[X]E[Y]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "Additionally: \n",
    "\n",
    "$ var (X) = E[X^2] - E[X]^2$\n",
    "\n",
    "Thus the following is also true:\n",
    "\n",
    "$ E[X^2] = var(X) + E[X]^2$\n",
    "\n",
    "This is important as some of these rules and terms can now be applied to the most recent expansion of this problem: \n",
    "\n",
    "$$ E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1cov(X,Y) - 2\\beta_1E[X]E[Y] + \\beta_0^2 + 2\\beta_0\\beta_1E[X] + \\beta_1^2 (var[X]) + \\beta_1^2(E[X])^2 $$\n",
    "\n",
    "With this, I have arrived at equation *ii*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCr46r9xwRXP"
   },
   "source": [
    "b) Prove that the MLE of $\\beta_0$ is $E[Y]- \\beta_1 E[X]$ by taking the derivative of _ii_ above, with respect to $\\beta_0$, setting the derivative to zero, and solving for $\\beta_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ul-PZyLbwTCQ"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "What I'm going to do is pull down equation *ii* from above and take the derivative with respect to Beta_0. In this process, terms without Beta_0 included will be dropped (but, for example, terms with both Beta_0 and Beta_1 are retained). Once I simplify the equation I will take derivatives with respect to Beta_0. Finally I'll set Beta_0 to equal 0. \n",
    "\n",
    "Beginning point: \n",
    "\n",
    "$ E[Y^2] - 2\\beta_0E[Y] - 2\\beta_1cov(X,Y) - 2\\beta_1E[X]E[Y] + \\beta_0^2 + 2\\beta_0\\beta_1E[X] + \\beta_1^2 (var[X]) + \\beta_1^2(E[X])^2 $\n",
    "\n",
    "The following terms from this equation will be dropped: \n",
    "\n",
    "$ E[Y^2]$\n",
    "\n",
    "$ -2\\beta_1cov[X,Y]$\n",
    "\n",
    "$ -2\\beta_1E[X]E[Y]$\n",
    "\n",
    "$ \\beta_1^2var[X]$\n",
    "\n",
    "$ \\beta_1^2E[X]^2$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "This leaves us with: \n",
    "\n",
    "$ -2\\beta_0E[Y] + \\beta_0^2 + 2\\beta_0\\beta_1E[X]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "\n",
    "For each term I will show the process of taking the derivative separately and then merge the final terms in my next step: \n",
    "\n",
    "First term: \n",
    "\n",
    "$ -2\\beta_0E[Y] =$\n",
    "\n",
    "$-2\\beta_0^1E[Y] =$\n",
    "\n",
    "$1*-2\\beta_0^{1-1}E[Y] =$\n",
    "\n",
    "$1*-2\\beta_0^0E[Y] =$\n",
    "\n",
    "$1*-2*E[Y] =$\n",
    "\n",
    "$ -2E[Y]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Second term: \n",
    "$\\beta_0^2 =$\n",
    "\n",
    "$2*\\beta_0^{2-1} =$\n",
    "\n",
    "$2*\\beta_0^1 =$\n",
    "\n",
    "$2\\beta_0$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Third term: \n",
    "$ 2\\beta_0\\beta_1E[X]= $\n",
    "\n",
    "$ 2\\beta_0^1\\beta_1E[X] = $\n",
    "\n",
    "$ 1*2\\beta_0^{1-1}\\beta_1E[X] = $\n",
    "\n",
    "$ 1*2\\beta_0^0\\beta_1E[X] = $\n",
    "\n",
    "$ 2\\beta_1E[X]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Thus, our derivative with respect to Beta_0 is: \n",
    "$ f(\\beta_0) = -2E[Y] + 2\\beta_0 + 2\\beta_1E[X]$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "Setting f(Beta_0) to 0, I can solve for Beta_0: \n",
    "$ -2E[Y] + 2\\beta_0 + 2\\beta_1E[X] = 0 $\n",
    "\n",
    "$ 2(-E[Y] + \\beta_0 + \\beta_1E[X]) = 0$\n",
    "\n",
    "$ \\frac{2(-E[Y] + \\beta_0 + \\beta_1E[X])}{2} = \\frac{0}{2}$\n",
    "\n",
    "$ -E[Y] + \\beta_0 + \\beta_1E[X] = 0$\n",
    "\n",
    "$ -E[Y] + \\beta_0 -\\beta_0 + \\beta_1E[X] = 0 -\\beta_0$\n",
    "\n",
    "$ -\\beta_0 = -E[Y]+ \\beta_1E[X]$\n",
    "\n",
    "$ \\frac{-\\beta_0}{-1} = \\frac{(-E[Y]+ \\beta_1E[X])}{-1}$\n",
    "\n",
    "$$ \\beta_0 = E[Y] - \\beta_1E[X]$$\n",
    "\n",
    "With this, I have arrived to the conclusion that MLE of Beta_0 is equal to the equation listed in the instructions for part 1B. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uv4Z7afw4gB"
   },
   "source": [
    "c) Prove that the MLE for $\\beta_1$ is $Cov[X,Y]/Var[X]$ by taking the derivative of equation _ii_ above, with respect to $\\beta_1$, setting the derivative to zero, and solving for $\\beta_1$. *Hint: after you've simplified / expanded a bit, plug in the solution for $\\beta_0$ from part b.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWTFZ6ZSw6sh"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "Again I'm going to pull down equation *ii* from above and take the derivative with respect to Beta_1. In this process, terms without Beta_1 will be dropped (but, for example, terms with both Beta_0 and Beta_1 are retained). Once I simplify the equation I will take derivatives with respect to Beta_1. Finally I'll set Beta_1 to equal 0.\n",
    "\n",
    "The following terms from this equation will be dropped:\n",
    "\n",
    "$E[Y^2]$\n",
    "\n",
    "$-2\\beta_0E[Y]$\n",
    "\n",
    "$ \\beta_0^2$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "This leaves us with: \n",
    "\n",
    "$ -2\\beta_1cov(X,Y) - 2\\beta_1E[X]E[Y] + 2\\beta_0\\beta_1E[X] + \\beta_1^2var(X) + \\beta_1^2E[X]^2$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "For each term I will show the process of taking the derivative separately and then merge the final terms in my next step:\n",
    "<p>&nbsp;</p>\n",
    "First term: \n",
    "\n",
    "$ -2\\beta_1cov(X,Y) =$\n",
    "\n",
    "$ -2\\beta_1^1cov(X,Y) =$\n",
    "\n",
    "$ 1 * -2\\beta_1^{1-1}cov(X,Y) =$\n",
    "\n",
    "$ 1 * -2\\beta_1^0cov(X,Y) =$\n",
    "\n",
    "$ -2cov(X,Y)$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Second term: \n",
    "\n",
    "$ - 2\\beta_1E[X]E[Y] =$\n",
    "\n",
    "$ -2\\beta_1^1E[X]E[Y] =$\n",
    "\n",
    "$ 1 * -2 \\beta_1^{1-1}E[X]E[Y] =$\n",
    "\n",
    "$ 1* -2 \\beta_1^0 E[X]E[Y] =$\n",
    "\n",
    "$ -2E[X]E[Y]$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Third term: \n",
    "\n",
    "$ 2\\beta_0\\beta_1E[X]$\n",
    "\n",
    "$ 2\\beta_0\\beta_1^1E[X]$\n",
    "\n",
    "$ 1*2\\beta_0\\beta_1^{1-1}E[X]$\n",
    "\n",
    "$ 1*2\\beta_0\\beta_1^0E[X]$\n",
    "\n",
    "$ 2\\beta_0E[X]$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Fourth term: \n",
    "$\\beta_1^2var(X)$\n",
    "\n",
    "$ 2\\beta_1^{2-1}var(X)$\n",
    "\n",
    "$2\\beta_1^1var(X)$\n",
    "\n",
    "$2\\beta_1var(X)$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Fifth term: \n",
    "$\\beta_1^2E[X]^2$\n",
    "\n",
    "$2\\beta_1^{2-1}E[X]^2$\n",
    "\n",
    "$2\\beta_1^1E[X]^2$\n",
    "\n",
    "$2\\beta_1E[X]^2$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Thus, our derivative with respect to Beta_1 is:\n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) - 2E[X]E[Y] + 2\\beta_0E[X] + 2\\beta_1var(X) + 2\\beta_1E[(X)]^2$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Next I am going to use the equation generated in part 1B and plug in my answer for part 1B as a Beta_0 equivalent. The only difference between the equation below and equation above is that instead of Beta_0 in the 3rd term, you see the Beta_0 derivative (see part 1B).  \n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) -2E[X]E[Y] + 2E[X](E[Y] - \\beta_1E[X]) + 2\\beta_1var(X) + 2\\beta_1E[X]^2 $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Next I'm going to distribute 2E[X] in the 3rd term: \n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) -2E[X]E[Y] + 2E[X]E[Y] - 2\\beta_1E[X]^2 + 2\\beta_1var(X) + 2\\beta_1E[X]^2 $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "I can combine some terms with each other, effectively eliminating them, to reduce this equation: \n",
    "\n",
    "$ f(\\beta_1) = -2cov(X,Y) + 2\\beta_1var(X) $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Now I'll set the derivative of Beta_1 to 0 and solve for Beta_1:\n",
    "\n",
    "$ -2cov(X,Y) + 2\\beta_1var(X) = 0 $\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Pull out 2 from both terms: \n",
    "\n",
    "$ 2(-cov(X,Y) + \\beta_1var(X)) = 0$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Divide both sides of equation by 2: \n",
    "\n",
    "$ \\frac{2(-cov(X,Y) + \\beta_1var(X))}{2} = \\frac{0}{2}$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Begin to isolate Beta_1 but adding Cov(X,Y) to both sides of the equation: \n",
    "\n",
    "$ -cov(X,Y) + cov(X,Y) + \\beta_1var(X) = 0 + cov(X,Y)$\n",
    "\n",
    "$ \\beta_1var(X) = cov(X,Y)$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Divide both sides of the equation by var(X) to isoalte Beta_1:\n",
    "$ \\frac{\\beta_1var(X)}{var(X)} = \\frac{cov(X,Y)}{var(X)}$\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "We are left with: \n",
    "    <p>&nbsp;</p>\n",
    "\n",
    "$$ \\beta_1 = \\frac{cov(X,Y)}{var(X)}$$\n",
    "\n",
    "With this, I have arrived to the conclusion that MLE of Beta_1 is equal to the equation listed in the instructions for part 1C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66X264ZpDF58"
   },
   "source": [
    "---\n",
    "## 2. Connecting to data (4 points)\n",
    "\n",
    "Now let's connect this to some real data. Once again we'll be using the  **unrestricted_trimmed_1_7_2020_10_50_44.csv** file from the *Homework/hcp_data* folder in the class GitHub repository. \n",
    "\n",
    "â€‹\n",
    "This data is a portion of the [Human Connectome Project database](http://www.humanconnectomeproject.org/). It provides measures of cognitive tasks and brain morphology measurements from 1206 participants. The full description of each variable is provided in the **HCP_S1200_DataDictionary_April_20_2018.csv** file in the *Homework/hcp_data* folder in the class GitHub repository. \n",
    "\n",
    "a) Use the `setwd` and `read.csv` functions to load data from the **unrestricted_trimmed_1_7_2020_10_50_44.csv** file. Then use the `tidyverse` tools make a new dataframe `d1` that only inclues the subject ID (`Subject`), Flanker Task performance (`Flanker_Unadj`), and total grey matter volume (`FS_Total_GM_Vol`) variables and remove all _NA_ values.\n",
    "\n",
    "Use the `head` function to look at the first few rows of each data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5637,
     "status": "ok",
     "timestamp": 1616440721755,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 240
    },
    "id": "PZ0lngBjDF58",
    "outputId": "a3c4f688-d665-4d79-8250-56c4d45465e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 Ã— 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>n_NA</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 Ã— 1\n",
       "\\begin{tabular}{l}\n",
       " n\\_NA\\\\\n",
       " <int>\\\\\n",
       "\\hline\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 Ã— 1\n",
       "\n",
       "| n_NA &lt;int&gt; |\n",
       "|---|\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  n_NA\n",
       "1 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 Ã— 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>n_NA</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 Ã— 1\n",
       "\\begin{tabular}{l}\n",
       " n\\_NA\\\\\n",
       " <int>\\\\\n",
       "\\hline\n",
       "\t 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 Ã— 1\n",
       "\n",
       "| n_NA &lt;int&gt; |\n",
       "|---|\n",
       "| 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  n_NA\n",
       "1 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 Ã— 500</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Subject</th><th scope=col>Release</th><th scope=col>Acquisition</th><th scope=col>Gender</th><th scope=col>Age</th><th scope=col>MMSE_Score</th><th scope=col>PSQI_Score</th><th scope=col>PSQI_Comp1</th><th scope=col>PSQI_Comp2</th><th scope=col>PSQI_Comp3</th><th scope=col>â‹¯</th><th scope=col>Noise_Comp</th><th scope=col>Odor_Unadj</th><th scope=col>Odor_AgeAdj</th><th scope=col>PainIntens_RawScore</th><th scope=col>PainInterf_Tscore</th><th scope=col>Taste_Unadj</th><th scope=col>Taste_AgeAdj</th><th scope=col>Mars_Log_Score</th><th scope=col>Mars_Errs</th><th scope=col>Mars_Final</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>â‹¯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>100004</td><td>S900</td><td>Q06</td><td>M</td><td>22-25</td><td>29</td><td>8</td><td>1</td><td>2</td><td>2</td><td>â‹¯</td><td>5.2</td><td>101.12</td><td> 86.45</td><td>2</td><td>45.9</td><td>107.17</td><td>105.31</td><td>1.80</td><td>0</td><td>1.80</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>100206</td><td>S900</td><td>Q11</td><td>M</td><td>26-30</td><td>30</td><td>6</td><td>1</td><td>1</td><td>1</td><td>â‹¯</td><td>6.0</td><td>108.79</td><td> 97.19</td><td>1</td><td>49.7</td><td> 72.63</td><td> 72.03</td><td>1.84</td><td>0</td><td>1.84</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>100307</td><td>Q1  </td><td>Q01</td><td>F</td><td>26-30</td><td>29</td><td>4</td><td>1</td><td>0</td><td>1</td><td>â‹¯</td><td>3.6</td><td>101.12</td><td> 86.45</td><td>0</td><td>38.6</td><td> 71.69</td><td> 71.76</td><td>1.76</td><td>0</td><td>1.76</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>100408</td><td>Q3  </td><td>Q03</td><td>M</td><td>31-35</td><td>30</td><td>4</td><td>1</td><td>1</td><td>0</td><td>â‹¯</td><td>2.0</td><td>108.79</td><td> 98.04</td><td>2</td><td>52.6</td><td>114.01</td><td>113.59</td><td>1.76</td><td>2</td><td>1.68</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>100610</td><td>S900</td><td>Q08</td><td>M</td><td>26-30</td><td>30</td><td>4</td><td>1</td><td>1</td><td>0</td><td>â‹¯</td><td>2.0</td><td>122.25</td><td>110.45</td><td>0</td><td>38.6</td><td> 84.84</td><td> 85.31</td><td>1.92</td><td>1</td><td>1.88</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>101006</td><td>S500</td><td>Q06</td><td>F</td><td>31-35</td><td>28</td><td>2</td><td>1</td><td>1</td><td>0</td><td>â‹¯</td><td>6.0</td><td>122.25</td><td>111.41</td><td>0</td><td>38.6</td><td>123.80</td><td>123.31</td><td>1.80</td><td>0</td><td>1.80</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 Ã— 500\n",
       "\\begin{tabular}{r|lllllllllllllllllllll}\n",
       "  & Subject & Release & Acquisition & Gender & Age & MMSE\\_Score & PSQI\\_Score & PSQI\\_Comp1 & PSQI\\_Comp2 & PSQI\\_Comp3 & â‹¯ & Noise\\_Comp & Odor\\_Unadj & Odor\\_AgeAdj & PainIntens\\_RawScore & PainInterf\\_Tscore & Taste\\_Unadj & Taste\\_AgeAdj & Mars\\_Log\\_Score & Mars\\_Errs & Mars\\_Final\\\\\n",
       "  & <int> & <chr> & <chr> & <chr> & <chr> & <int> & <int> & <int> & <int> & <int> & â‹¯ & <dbl> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 100004 & S900 & Q06 & M & 22-25 & 29 & 8 & 1 & 2 & 2 & â‹¯ & 5.2 & 101.12 &  86.45 & 2 & 45.9 & 107.17 & 105.31 & 1.80 & 0 & 1.80\\\\\n",
       "\t2 & 100206 & S900 & Q11 & M & 26-30 & 30 & 6 & 1 & 1 & 1 & â‹¯ & 6.0 & 108.79 &  97.19 & 1 & 49.7 &  72.63 &  72.03 & 1.84 & 0 & 1.84\\\\\n",
       "\t3 & 100307 & Q1   & Q01 & F & 26-30 & 29 & 4 & 1 & 0 & 1 & â‹¯ & 3.6 & 101.12 &  86.45 & 0 & 38.6 &  71.69 &  71.76 & 1.76 & 0 & 1.76\\\\\n",
       "\t4 & 100408 & Q3   & Q03 & M & 31-35 & 30 & 4 & 1 & 1 & 0 & â‹¯ & 2.0 & 108.79 &  98.04 & 2 & 52.6 & 114.01 & 113.59 & 1.76 & 2 & 1.68\\\\\n",
       "\t5 & 100610 & S900 & Q08 & M & 26-30 & 30 & 4 & 1 & 1 & 0 & â‹¯ & 2.0 & 122.25 & 110.45 & 0 & 38.6 &  84.84 &  85.31 & 1.92 & 1 & 1.88\\\\\n",
       "\t6 & 101006 & S500 & Q06 & F & 31-35 & 28 & 2 & 1 & 1 & 0 & â‹¯ & 6.0 & 122.25 & 111.41 & 0 & 38.6 & 123.80 & 123.31 & 1.80 & 0 & 1.80\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 Ã— 500\n",
       "\n",
       "| <!--/--> | Subject &lt;int&gt; | Release &lt;chr&gt; | Acquisition &lt;chr&gt; | Gender &lt;chr&gt; | Age &lt;chr&gt; | MMSE_Score &lt;int&gt; | PSQI_Score &lt;int&gt; | PSQI_Comp1 &lt;int&gt; | PSQI_Comp2 &lt;int&gt; | PSQI_Comp3 &lt;int&gt; | â‹¯ â‹¯ | Noise_Comp &lt;dbl&gt; | Odor_Unadj &lt;dbl&gt; | Odor_AgeAdj &lt;dbl&gt; | PainIntens_RawScore &lt;int&gt; | PainInterf_Tscore &lt;dbl&gt; | Taste_Unadj &lt;dbl&gt; | Taste_AgeAdj &lt;dbl&gt; | Mars_Log_Score &lt;dbl&gt; | Mars_Errs &lt;int&gt; | Mars_Final &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 100004 | S900 | Q06 | M | 22-25 | 29 | 8 | 1 | 2 | 2 | â‹¯ | 5.2 | 101.12 |  86.45 | 2 | 45.9 | 107.17 | 105.31 | 1.80 | 0 | 1.80 |\n",
       "| 2 | 100206 | S900 | Q11 | M | 26-30 | 30 | 6 | 1 | 1 | 1 | â‹¯ | 6.0 | 108.79 |  97.19 | 1 | 49.7 |  72.63 |  72.03 | 1.84 | 0 | 1.84 |\n",
       "| 3 | 100307 | Q1   | Q01 | F | 26-30 | 29 | 4 | 1 | 0 | 1 | â‹¯ | 3.6 | 101.12 |  86.45 | 0 | 38.6 |  71.69 |  71.76 | 1.76 | 0 | 1.76 |\n",
       "| 4 | 100408 | Q3   | Q03 | M | 31-35 | 30 | 4 | 1 | 1 | 0 | â‹¯ | 2.0 | 108.79 |  98.04 | 2 | 52.6 | 114.01 | 113.59 | 1.76 | 2 | 1.68 |\n",
       "| 5 | 100610 | S900 | Q08 | M | 26-30 | 30 | 4 | 1 | 1 | 0 | â‹¯ | 2.0 | 122.25 | 110.45 | 0 | 38.6 |  84.84 |  85.31 | 1.92 | 1 | 1.88 |\n",
       "| 6 | 101006 | S500 | Q06 | F | 31-35 | 28 | 2 | 1 | 1 | 0 | â‹¯ | 6.0 | 122.25 | 111.41 | 0 | 38.6 | 123.80 | 123.31 | 1.80 | 0 | 1.80 |\n",
       "\n"
      ],
      "text/plain": [
       "  Subject Release Acquisition Gender Age   MMSE_Score PSQI_Score PSQI_Comp1\n",
       "1 100004  S900    Q06         M      22-25 29         8          1         \n",
       "2 100206  S900    Q11         M      26-30 30         6          1         \n",
       "3 100307  Q1      Q01         F      26-30 29         4          1         \n",
       "4 100408  Q3      Q03         M      31-35 30         4          1         \n",
       "5 100610  S900    Q08         M      26-30 30         4          1         \n",
       "6 101006  S500    Q06         F      31-35 28         2          1         \n",
       "  PSQI_Comp2 PSQI_Comp3 â‹¯ Noise_Comp Odor_Unadj Odor_AgeAdj PainIntens_RawScore\n",
       "1 2          2          â‹¯ 5.2        101.12      86.45      2                  \n",
       "2 1          1          â‹¯ 6.0        108.79      97.19      1                  \n",
       "3 0          1          â‹¯ 3.6        101.12      86.45      0                  \n",
       "4 1          0          â‹¯ 2.0        108.79      98.04      2                  \n",
       "5 1          0          â‹¯ 2.0        122.25     110.45      0                  \n",
       "6 1          0          â‹¯ 6.0        122.25     111.41      0                  \n",
       "  PainInterf_Tscore Taste_Unadj Taste_AgeAdj Mars_Log_Score Mars_Errs\n",
       "1 45.9              107.17      105.31       1.80           0        \n",
       "2 49.7               72.63       72.03       1.84           0        \n",
       "3 38.6               71.69       71.76       1.76           0        \n",
       "4 52.6              114.01      113.59       1.76           2        \n",
       "5 38.6               84.84       85.31       1.92           1        \n",
       "6 38.6              123.80      123.31       1.80           0        \n",
       "  Mars_Final\n",
       "1 1.80      \n",
       "2 1.84      \n",
       "3 1.76      \n",
       "4 1.68      \n",
       "5 1.88      \n",
       "6 1.80      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "setwd(\"~/Documents/GitHub/Goldberg_DSPN_S22/hcp_data\")\n",
    "hcp_df1 <- read.csv(\"unrestricted_trimmed_1_7_2020_10_50_44.csv\")\n",
    "\n",
    "hcp_df1 %>% select(Subject, Flanker_Unadj, FS_Total_GM_Vol) %>%\n",
    "drop_na() -> d1\n",
    "\n",
    "## Count # of NAs within the Flanker_unadj variable\n",
    "summarize(d1, n_NA = sum(is.na(Flanker_Unadj)))\n",
    "## 0, yay!\n",
    "\n",
    "## Count # of NAs within the FS_Total_GM_Vol variable\n",
    "summarize(d1, n_NA = sum(is.na(FS_Total_GM_Vol)))\n",
    "## 0, yay!\n",
    "\n",
    "head(hcp_df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3owDQ0U2Ewn"
   },
   "source": [
    "b) Now we're going to see if the solutions we proved above actually line up with the model fit that R gives us (it should...). Calculate what the $\\beta_0$ and $\\beta_1$ coefficients should be for a simple linear regression model using `Flanker_Unadj` as $Y$ and `FS_Total_GM_Vol` as $X$. Use the formulas we derived above ($\\beta_1 = Cov[XY]/Var[X]$ , $\\beta_0 = E[Y] - \\beta_1E[X]$). Then use `lm()` to compare the coefficients you calculated with the ones R gives you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1614907277511,
     "user": {
      "displayName": "Patience Stevens",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi-_9ZqhIFhAv1oMehJNvNuIKSTyrFQHzjxQKhx=s64",
      "userId": "01994571539255174942"
     },
     "user_tz": 300
    },
    "id": "mWvD8shRDF5_",
    "outputId": "02f91143-c36c-4e9d-dce1-d81f4cbd71b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.10996547106463e-05"
      ],
      "text/latex": [
       "3.10996547106463e-05"
      ],
      "text/markdown": [
       "3.10996547106463e-05"
      ],
      "text/plain": [
       "[1] 3.109965e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "90.2564608190943"
      ],
      "text/latex": [
       "90.2564608190943"
      ],
      "text/markdown": [
       "90.2564608190943"
      ],
      "text/plain": [
       "[1] 90.25646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = Flanker_Unadj ~ FS_Total_GM_Vol, data = hcp_df1)\n",
       "\n",
       "Coefficients:\n",
       "    (Intercept)  FS_Total_GM_Vol  \n",
       "      9.026e+01        3.110e-05  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Creating vectors for X (FS_Total_GM_Vol) and Y (Flanker_Unadj)\n",
    "X <- d1$FS_Total_GM_Vol\n",
    "Y <- d1$Flanker_Unadj\n",
    "\n",
    "## First I'm going to calculate the Beta_1 coefficient. There are 2 terms we need to calculate Beta_1:\n",
    "## First we need Cov(X,Y). Second we need Var(X).\n",
    "## We know that Cov(X,Y) = E[(X-EX)(Y-EY)]. \n",
    "## We also know that Var(X) is equal to E[(X-EX)^2]\n",
    "## E here can be taken to mean the average. Thus I am going to assign these equations to functions\n",
    "## and use those functions to calculate Beta_1:\n",
    "\n",
    "covXY <- mean((X-mean(X))*(Y-mean(Y)))\n",
    "varX <- mean((X-mean(X))^2)\n",
    "\n",
    "Beta_1 = covXY/varX\n",
    "Beta_1\n",
    "## Beta_1 = 3.11e-05\n",
    "\n",
    "## Next I am going to calculate the Beta_0 coefficient using the Beta_1 coefficient derived above. \n",
    "## Beta_0 is equal to the mean of Y minus the Beta_1 coefficient times the mean of (X). \n",
    "\n",
    "Beta_0 = mean(Y)-(Beta_1*(mean(X)))\n",
    "Beta_0\n",
    "## Beta_0 = 90.26\n",
    "\n",
    "\n",
    "## Now I am going to check my calculations by generating a simple linear model predicting\n",
    "## Y from X and comparing the model coefficients with the coefficients calculated above: \n",
    "\n",
    "lm(Flanker_Unadj ~ FS_Total_GM_Vol, data = hcp_df1)\n",
    "\n",
    "## The intercept value, also known as Beta_0, per the linear model is equal to 9.026e+01 = 90.26. \n",
    "## This is consistent with my calculated Beta_0 above.\n",
    "\n",
    "## The Beta_1 coefficient is equal to 3.110e-05, which is also consistent with my calculated\n",
    "## Beta_1 above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcnXbsZvDF6B"
   },
   "source": [
    "**DUE:** 5pm EST, March 15, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG5swCweDF6B"
   },
   "source": [
    "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here. \n",
    "> Monique Tardif (world traveler, volleyball queen), Avital Pelakh, Sara Jaramillo, Danielle Fox, Ellie Ketura\n",
    "\n",
    "> Special shoutout to my very kind and patient boyfriend, Matthew Schnur, for teaching me calculus basics. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework5_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
